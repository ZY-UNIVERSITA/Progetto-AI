## Panoramica della rete (v10)

| Chiave | Valore |
|--------|--------|
| Architettura | Conv-BN-ReLU-Pool (16 → 32) → **Conv-BN-ReLU 64** → AdaptiveAvgPool 1x1 → Flatten → Dropout 0.3 → FC 128 → Dropout 0.3 → FC(out) |
| Parametri totali | **≈ 35 k** |
| Optimizer | Adam (lr 1 e-5 → warm-up a 5 e-4) |
| Scheduler | StepLR(step = 10, γ = 0.1) |
| Batch | 32 |
| Epoch previsti | 50 |
| Epoch eseguiti | 24 |

---

### Andamento addestramento

| Ep | LR | Acc-train | Acc-val | Loss-train | Loss-val |
|----|----|-----------|---------|------------|----------|
| 1  | 1e-5  | 3.28%  | 4.89%  | 3.41 | 3.40 |
| 5  | 2.3e-4| 19.7%  | 41.50% | 2.74 | 2.28 |
| 10 | 5e-4  | 66.0%  | 77.00% | 0.95 | 0.67 |
| 16 | 5e-4  | 75.0%  | 72.9% | 0.68 | 0.69 |
| 20 | 5e-5  | 78.7%  | 91.06%| 0.60 | 0.34 |
| 24 | 5e-5  | 80.02% | 90.93% | 0.56 | 0.332 |

---

## Osservazioni chiave

1. **Piccolo miglioramento vs v9**  
   - +0.8% di val-acc (92.25 vs 91.45) grazie a MaxPool rimosso nel terzo blocco → feature map 16x16 anziché 8x8 quindi l'immagine ha più dettagli da dare in pasto all'Average pooling.
   - Il modello rimane troppo piccolo per modellare il dominio e la sua accuratezza e ne risente.

---

## Confronto tra le ultime versioni

|  | v8 | v9 | **v10** |
|---|---|---|---|
| Parametri | 552 k | 35 k | 35 k |
| Val-Acc | **99.43%** | 91.45% | 92.25% |
| Train-Acc | **99.74%** | 79.65% | 79.63% |
| Gap T-V | 0.31% | 11.8% | **12.6%** |


